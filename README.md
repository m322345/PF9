![Entete](images/projet.png)

# 📌 Traitement de Données dans un Environnement Big Data sur le Cloud

## 📖 Contexte
La start-up **Fruits!** est spécialisée dans l'**AgriTech** et le développement de **robots cueilleurs intelligents**. Pour sensibiliser le grand public à la **biodiversité des fruits**, l’entreprise souhaite développer une **application mobile** capable d’identifier les fruits à partir d’une simple photo.

L'objectif de cette mission est de **mettre en place une chaîne de traitement Big Data** sur le **cloud AWS**, afin de préparer une infrastructure scalable pour le futur moteur de classification des images de fruits.

## 🎯 Objectifs du Projet
- ✅ Reprendre et améliorer un **notebook PySpark** existant.
- ✅ Mise en place d'un **cluster EMR AWS** pour traiter de grandes quantités d’images.
- ✅ Ajout d'une **réduction de dimension PCA** pour optimiser le stockage et les calculs.
- ✅ Assurer la **conformité RGPD** en paramétrant les serveurs en Europe.
- ✅ Optimiser l’architecture pour **minimiser les coûts d’utilisation du cloud**.

## 🛠️ Étapes du Projet

### 1️⃣ **Analyse du Notebook Existant**
- Examiner le **travail réalisé par l’alternant**.
- Compléter et commenter le **script PySpark** pour garantir sa clarté.

### 2️⃣ **Déploiement d’une Infrastructure Big Data sur AWS**
- Identification des **services AWS pertinents** (EMR, S3, IAM).
- Configuration d'un **cluster EMR** et connexion du notebook pour exécuter les traitements.
- Optimisation de l’utilisation du **cloud** pour limiter les coûts.

### 3️⃣ **Amélioration du Traitement PySpark**
- Intégration d'une **réduction de dimension PCA** pour optimiser les performances.
- Implémentation d'un **broadcast des poids TensorFlow** pour une meilleure distribution du modèle.

### 4️⃣ **Démonstration et Documentation**
- Vérification que les **données et résultats sont bien organisés et accessibles**.
- Réddaction d'une **présentation claire** de l’architecture et du pipeline de traitement.
- Prépareration d'une **démonstration technique** fluide et structurée.

## 📦 Livrables Attendus
- ✅ Un **notebook PySpark** documenté et optimisé.
- ✅ Une **infrastructure cloud fonctionnelle** avec AWS EMR.
- ✅ Un **traitement distribué scalable** pour le futur moteur de classification.
- ✅ Une **présentation détaillée** de l’architecture et des choix technologiques.

## 🚀 Objectif Final
Développer une **première version scalable** du pipeline Big Data sur AWS, optimisée pour le traitement massif d’images de fruits, en vue d’un **moteur de classification à grande échelle**.

---
- 👥 **Compétences requises** : PySpark, AWS EMR, PCA, TensorFlow.
- 📅 **Technologies** : AWS (EMR, S3, IAM), PySpark, Machine Learning.
- 🌍 **Source des données** : Issues du site Kagle [Fruits-360 dataset](https://www.kaggle.com/datasets/moltean/fruits)